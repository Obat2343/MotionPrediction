{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import tensorboardX\n",
    "import torch\n",
    "import yaml\n",
    "import shutil\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn as nn\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kornia requires version >= 3.6. your version 3.6\n"
     ]
    }
   ],
   "source": [
    "from pycode.dataset import RLBench_dataset, Softargmax_dataset, imageaug_full_transform, train_val_split, pose_aug\n",
    "from pycode.config import _C as cfg\n",
    "from pycode.model.Hourglass import stacked_hourglass_model\n",
    "from pycode.loss.mp_loss import Train_Loss_sequence_hourglass\n",
    "from pycode.misc import save_outputs, build_model_MP, build_dataset_MP, build_optimizer, str2bool, save_args, save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configration file ../configs/RLBench_MP.yaml\n"
     ]
    }
   ],
   "source": [
    "# parser\n",
    "parser = argparse.ArgumentParser(description='parser for image generator')\n",
    "parser.add_argument('--config_file', type=str, default='', metavar='FILE', help='path to config file')\n",
    "parser.add_argument('--log_step', type=int, default=10, help='')\n",
    "parser.add_argument('--save_step', type=int, default=100, help='')\n",
    "parser.add_argument('--eval_step', type=int, default=100, help='')\n",
    "parser.add_argument('--output_dirname', type=str, default='', help='')\n",
    "parser.add_argument('--checkpoint_path', type=str, default=None, help='')\n",
    "parser.add_argument('--log2wandb', type=str2bool, default=True)\n",
    "args = parser.parse_args(args=['--config_file','../configs/RLBench_MP.yaml','--output_dirname','hoge', '--log2wandb','False'])\n",
    "# args = parser.parse_args(args=['--checkpoint_path','output/2020-04-02_18:28:18.736004/model_log/checkpoint_epoch9_iter11'])\n",
    "\n",
    "# get cfg data\n",
    "if len(args.config_file) > 0:\n",
    "    print('Loaded configration file {}'.format(args.config_file))\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "\n",
    "# define output dirname\n",
    "if len(args.output_dirname) == 0:\n",
    "    dt_now = datetime.datetime.now()\n",
    "    output_dirname = str(dt_now.date()) + '_' + str(dt_now.time())\n",
    "else:\n",
    "    output_dirname = args.output_dirname\n",
    "    \n",
    "cfg.BASIC.OUTPUT_DIR = os.path.join(cfg.BASIC.OUTPUT_DIR, cfg.DATASET.NAME, output_dirname)\n",
    "cfg.freeze()\n",
    "\n",
    "# define save model path\n",
    "model_path = os.path.join(cfg.BASIC.OUTPUT_DIR, 'model_log')\n",
    "\n",
    "# make output dir\n",
    "os.makedirs(cfg.BASIC.OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# copy config file\n",
    "if len(args.config_file) > 0:\n",
    "    shutil.copy(args.config_file,cfg.BASIC.OUTPUT_DIR)\n",
    "\n",
    "# save args\n",
    "argsfile_path = os.path.join(cfg.BASIC.OUTPUT_DIR, \"args.txt\")\n",
    "save_args(args,argsfile_path)\n",
    "\n",
    "# set seed and cuda\n",
    "torch.manual_seed(cfg.BASIC.SEED)\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(cfg.BASIC.DEVICE)\n",
    "\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.manual_seed(cfg.BASIC.SEED)\n",
    "\n",
    "with open(args.config_file) as file:\n",
    "    obj = yaml.safe_load(file)\n",
    "\n",
    "if args.log2wandb:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    run = wandb.init(project='MotionPrediction-{}'.format(cfg.DATASET.NAME), entity='tendon', config=obj, save_code=True, name=args.output_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of future is 1 frame\n",
      "load json data\n",
      "length of future is 1 frame\n",
      "load json data\n"
     ]
    }
   ],
   "source": [
    "# set dataset\n",
    "train_dataset = build_dataset_MP(cfg, save_dataset=False, mode='train')\n",
    "val_dataset = build_dataset_MP(cfg, save_dataset=False, mode='val')\n",
    "\n",
    "# set dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=cfg.BASIC.BATCH_SIZE, shuffle=True, num_workers=cfg.BASIC.WORKERS)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=cfg.BASIC.BATCH_SIZE, shuffle=False, num_workers=cfg.BASIC.WORKERS)\n",
    "\n",
    "# set model\n",
    "model = build_model_MP(cfg)\n",
    "# wandb.watch(model, log_freq=5000)\n",
    "model = torch.nn.DataParallel(model, device_ids = list(range(cfg.BASIC.NUM_GPU)))\n",
    "# model = convert_model(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# set loss\n",
    "train_loss = Train_Loss_sequence_hourglass(cfg, device)\n",
    "val_loss = Train_Loss_sequence_hourglass(cfg, device)\n",
    "\n",
    "# set optimizer\n",
    "optimizer = build_optimizer(cfg, model, 'mp')\n",
    "scheduler = StepLR(optimizer, step_size=cfg.SCHEDULER.STEPLR.STEP_SIZE, gamma=cfg.SCHEDULER.STEPLR.GAMMA)\n",
    "\n",
    "# load checkpoint\n",
    "if args.checkpoint_path != None:\n",
    "    checkpoint_path = os.path.join(args.checkpoint_path, 'mp.pth')\n",
    "    \n",
    "    if cfg.LOAD_MODEL == 'all':\n",
    "        model, optimizer, start_epoch, start_iter, scheduler = load_checkpoint(model, checkpoint_path, optimizer=optimizer, scheduler=scheduler)\n",
    "    elif cfg.LOAD_MODEL == 'model_only':\n",
    "        model, _, _, _, _ = load_checkpoint(model, checkpoint_path)\n",
    "        start_epoch, start_iter = 0, 1\n",
    "else:\n",
    "    start_epoch, start_iter = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iter: 000010/550928000, LR: 0.00010, Cost: 10.28s, Eta: 6555 days, 22:50:01, Loss: 55.946618\n",
      "===> Iter: 000020/550928000, LR: 0.00010, Cost: 5.92s, Eta: 5165 days, 22:01:23, Loss: 55.901848\n",
      "===> Iter: 000030/550928000, LR: 0.00010, Cost: 5.81s, Eta: 4677 days, 23:41:22, Loss: 55.279611\n",
      "===> Iter: 000040/550928000, LR: 0.00010, Cost: 5.92s, Eta: 4451 days, 21:24:38, Loss: 54.814889\n",
      "===> Iter: 000050/550928000, LR: 0.00010, Cost: 5.87s, Eta: 4309 days, 23:50:14, Loss: 54.771715\n",
      "===> Iter: 000060/550928000, LR: 0.00010, Cost: 5.95s, Eta: 4224 days, 4:29:15, Loss: 52.478517\n",
      "===> Iter: 000070/550928000, LR: 0.00010, Cost: 5.88s, Eta: 4156 days, 15:31:18, Loss: 51.198046\n",
      "===> Iter: 000080/550928000, LR: 0.00010, Cost: 5.90s, Eta: 4107 days, 16:06:26, Loss: 48.254823\n",
      "===> Iter: 000090/550928000, LR: 0.00010, Cost: 5.92s, Eta: 4071 days, 0:25:39, Loss: 42.386750\n",
      "===> Iter: 000100/550928000, LR: 0.00010, Cost: 5.91s, Eta: 4040 days, 13:26:06, Loss: 40.930115\n",
      "validataion start\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "end = time.time()\n",
    "trained_time = 0\n",
    "max_iter = cfg.BASIC.MAX_EPOCH * len(train_dataloader)\n",
    "for epoch in range(start_epoch, cfg.BASIC.MAX_EPOCH):\n",
    "    for iteration, inputs in enumerate(train_dataloader, 1):\n",
    "        total_iteration = len(train_dataloader) * epoch + iteration\n",
    "            \n",
    "        # skip until start iter\n",
    "        if iteration < start_iter:\n",
    "            continue\n",
    "            \n",
    "        # optimize generator\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = train_loss(inputs, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # time setting\n",
    "        trained_time += time.time() - end\n",
    "        end = time.time() \n",
    "        \n",
    "        # save and print log\n",
    "        if total_iteration % args.log_step == 0:\n",
    "            log = train_loss.get_log()\n",
    "            eta_seconds = int((trained_time / total_iteration) * (max_iter - total_iteration))\n",
    "            \n",
    "            if args.log2wandb:\n",
    "                wandb.log(log,step=total_iteration)\n",
    "            \n",
    "            print('===> Iter: {:06d}/{:06d}, LR: {:.5f}, Cost: {:.2f}s, Eta: {}, Loss: {:.6f}'.format(total_iteration, \n",
    "                max_iter, optimizer.param_groups[0]['lr'], time.time() - tic, \n",
    "                str(datetime.timedelta(seconds=eta_seconds)), log['train/weight_loss']))\n",
    "            \n",
    "            train_loss.reset_log()\n",
    "            tic = time.time()\n",
    "            \n",
    "        # validataion\n",
    "        if total_iteration % args.eval_step == 0:\n",
    "            print('validataion start')\n",
    "            for iteration, inputs in enumerate(val_dataloader, 1):\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    _ = val_loss(inputs, outputs, mode='val')\n",
    "            \n",
    "            val_log = val_loss.get_log()\n",
    "            if args.log2wandb:\n",
    "                wandb.log(val_log,step=total_iteration)\n",
    "            \n",
    "            print('===> Iter: {:06d}/{:06d}, VAL Loss: {:.6f}'.format(total_iteration, max_iter, val_log['val/weight_loss']))\n",
    "            print('')\n",
    "            val_loss.reset_log()\n",
    "        \n",
    "        # save checkpoint\n",
    "        if total_iteration % args.save_step == 0:\n",
    "            checkpoint_dir = os.path.join(model_path,'checkpoint_epoch{}_iter{}'.format(epoch,iteration))\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            cp_path = os.path.join(checkpoint_dir, 'mp.pth')\n",
    "            save_checkpoint(model, optimizer, epoch, iteration, cp_path, scheduler)\n",
    "            \n",
    "            # save output image\n",
    "            for i, inputs in enumerate(train_dataloader, 1):\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    save_outputs(inputs, outputs, checkpoint_dir, i, cfg, mode='train')\n",
    "                    \n",
    "                if i >= 5:\n",
    "                    break\n",
    "            \n",
    "            for i, inputs in enumerate(val_dataloader, 1):\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    save_outputs(inputs, outputs, checkpoint_dir, i, cfg, mode='val')\n",
    "                    \n",
    "                if i >= 5:\n",
    "                    break        \n",
    "                \n",
    "    train_dataset.update_seed()\n",
    "    print(\"seed: {}\".format(train_dataset.seed))\n",
    "    start_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['rotation_matrix'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
