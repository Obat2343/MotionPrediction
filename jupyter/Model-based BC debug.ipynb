{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kornia requires version >= 3.6. your version 3.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import progressbar\n",
    "import numpy as np\n",
    "import datetime\n",
    "import shutil\n",
    "import yaml\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(\"../git/future-image-similarity\")\n",
    "\n",
    "import utils\n",
    "\n",
    "sys.path.append('../')\n",
    "from pycode.dataset import RLBench_dataset3\n",
    "from pycode.config import _C as cfg\n",
    "from pycode.misc import save_outputs, build_dataset_VP, build_optimizer, str2bool, save_args, save_checkpoint, load_checkpoint, Timer, Time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='learning rate')\n",
    "parser.add_argument('--beta1', default=0.9, type=float, help='momentum term for adam')\n",
    "parser.add_argument('--log_dir', default='logs', help='base directory to save logs')\n",
    "parser.add_argument('--model_dir', default='', help='base directory to save trained models')\n",
    "parser.add_argument('--name', default='', help='identifier for directory')\n",
    "parser.add_argument('--data_root', default='data', help='root directory for data')\n",
    "parser.add_argument('--niter', type=int, default=100, help='number of epochs to train for')\n",
    "parser.add_argument('--seed', default=1, type=int, help='manual seed')\n",
    "parser.add_argument('--epoch_size', type=int, default=600, help='epoch size')\n",
    "parser.add_argument('--image_width', type=int, default=256, help='the height / width of the input image to network')\n",
    "parser.add_argument('--channels', default=3, type=int)\n",
    "parser.add_argument('--dataset', default='lab_pose', help='predictor training data: lab_pose or gaz_pose')\n",
    "parser.add_argument('--rnn_size', type=int, default=256, help='dimensionality of hidden layer')\n",
    "parser.add_argument('--prior_rnn_layers', type=int, default=1, help='number of layers')\n",
    "parser.add_argument('--posterior_rnn_layers', type=int, default=1, help='number of layers')\n",
    "parser.add_argument('--z_dim', type=int, default=64, help='dimensionality of z_t')\n",
    "parser.add_argument('--g_dim', type=int, default=128, help='dimensionality of encoder output vector and decoder input vector')\n",
    "parser.add_argument('--beta', type=float, default=0.0001, help='weighting on KL to prior')\n",
    "parser.add_argument('--data_threads', type=int, default=5, help='number of data loading threads')\n",
    "parser.add_argument('--last_frame_skip', action='store_true', help='if true, skip connections go between frame t and frame t+t rather than last ground truth frame')\n",
    "\n",
    "parser.add_argument('--config_file', type=str, default='', metavar='FILE', help='path to config file')\n",
    "parser.add_argument('--output_dirname', type=str, default='', help='')\n",
    "parser.add_argument('--log_step', type=int, default=100, help='')\n",
    "parser.add_argument('--save_step', type=int, default=10000, help='')\n",
    "parser.add_argument('--eval_step', type=int, default=5000, help='')\n",
    "parser.add_argument('--log2wandb', type=str2bool, default=True)\n",
    "parser.add_argument('--wandb_group', type=str, default='') # e.g. compare_input\n",
    "parser.add_argument('--save_dataset', type=str2bool, default=False)\n",
    "parser.add_argument('--checkpoint_path', type=str, default=None, help='')\n",
    "\n",
    "args = parser.parse_args([\"--config_file\",\"../configs/RLBench_MBBC.yaml\",\"--output_dirname\",\"MBBC_random_len10\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configration file ../configs/RLBench_MBBC.yaml\n",
      "The specified output dir is already exists. Overwrite? y or n: y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtendon\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">MBBC_random_len10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/tendon/MotionPrediction-RLBench3-PickUpCup\" target=\"_blank\">https://wandb.ai/tendon/MotionPrediction-RLBench3-PickUpCup</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/tendon/MotionPrediction-RLBench3-PickUpCup/runs/249mtlue\" target=\"_blank\">https://wandb.ai/tendon/MotionPrediction-RLBench3-PickUpCup/runs/249mtlue</a><br/>\n",
       "                Run data is saved locally in <code>../output/RLBench3/wandb/run-20211012_203138-249mtlue</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# args.skip_factor = 10\n",
    "# args.n_past = 5 -> use cfg.PAST_LEN\n",
    "\n",
    "# if args.model_dir != '':\n",
    "#     # load model and continue training from checkpoint\n",
    "#     saved_model = torch.load('%s/model.pth' % args.model_dir)\n",
    "        \n",
    "#     optimizer = args.optimizer\n",
    "#     model_dir = args.model_dir\n",
    "#     opt = saved_model['opt']\n",
    "#     args.optimizer = optimizer\n",
    "#     args.model_dir = model_dir\n",
    "#     args.log_dir = '%s/continued' % args.log_dir\n",
    "# else:\n",
    "#     name = 'model_predictor'\n",
    "\n",
    "#     args.log_dir = '%s/%s/%s' % (args.log_dir, args.dataset, name)\n",
    "\n",
    "# os.makedirs('%s/gen/' % args.log_dir, exist_ok=True)\n",
    "\n",
    "# get cfg data\n",
    "if len(args.config_file) > 0:\n",
    "    print('Loaded configration file {}'.format(args.config_file))\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "\n",
    "# define output dirname\n",
    "if len(args.output_dirname) == 0:\n",
    "    dt_now = datetime.datetime.now()\n",
    "    output_dirname = str(dt_now.date()) + '_' + str(dt_now.time())\n",
    "else:\n",
    "    output_dirname = args.output_dirname\n",
    "\n",
    "output_dirname = os.path.join(cfg.BASIC.OUTPUT_DIR, cfg.DATASET.NAME, cfg.DATASET.RLBENCH.TASK_LIST[0], output_dirname)\n",
    "if os.path.exists(output_dirname):\n",
    "    while 1:\n",
    "        ans = input('The specified output dir is already exists. Overwrite? y or n: ')\n",
    "        if ans == 'y':\n",
    "            break\n",
    "        elif ans == 'n':\n",
    "            raise ValueError(\"Please specify correct output dir\")\n",
    "        else:\n",
    "            print('please type y or n')\n",
    "\n",
    "cfg.freeze()\n",
    "\n",
    "# define save model path\n",
    "model_path = os.path.join(output_dirname, 'model_log')\n",
    "\n",
    "# make output dir\n",
    "os.makedirs(output_dirname, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# copy config file\n",
    "if len(args.config_file) > 0:\n",
    "    shutil.copy(args.config_file,output_dirname)\n",
    "\n",
    "# save args\n",
    "argsfile_path = os.path.join(output_dirname, \"args.txt\")\n",
    "save_args(args,argsfile_path)\n",
    "\n",
    "# set seed and cuda\n",
    "random.seed(cfg.BASIC.SEED)\n",
    "torch.manual_seed(cfg.BASIC.SEED)\n",
    "torch.cuda.manual_seed_all(cfg.BASIC.SEED)\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(cfg.BASIC.DEVICE)\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# set wandb\n",
    "with open(args.config_file) as file:\n",
    "    obj = yaml.safe_load(file)\n",
    "\n",
    "if args.log2wandb:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    if args.wandb_group == '':\n",
    "        group = None\n",
    "    else:\n",
    "        group = args.wandb_group\n",
    "    run = wandb.init(project='MotionPrediction-{}-{}'.format(cfg.DATASET.NAME, cfg.DATASET.RLBENCH.TASK_LIST[0]), entity='tendon',\n",
    "                    config=obj, save_code=True, name=args.output_dirname, dir=os.path.join(cfg.BASIC.OUTPUT_DIR, cfg.DATASET.NAME),\n",
    "                    group=group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of future is 1 frame\n",
      "There is no json data\n",
      "create json data\n",
      "done\n",
      "save json data\n",
      "done\n",
      "length of future is 1 frame\n",
      "load json data\n"
     ]
    }
   ],
   "source": [
    "# set dataset\n",
    "train_dataset = build_dataset_VP(cfg, save_dataset=args.save_dataset, mode='train')\n",
    "val_dataset = build_dataset_VP(cfg, save_dataset=args.save_dataset, mode='val')\n",
    "\n",
    "# set dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=cfg.BASIC.BATCH_SIZE, shuffle=True, num_workers=cfg.BASIC.WORKERS)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=cfg.BASIC.BATCH_SIZE, shuffle=True, num_workers=cfg.BASIC.WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv_network(\n",
       "  (pre_lstm): Sequential(\n",
       "    (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Tanh()\n",
       "    (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.model_predictor import gaussian_lstm as lstm_model\n",
    "\n",
    "lstm_input_size = int(((args.image_width / 16) - 2)**2 * args.g_dim)\n",
    "lstm_output_size = int(((args.image_width / 16) - 2)**2 * 16)\n",
    "\n",
    "if args.model_dir != '':\n",
    "    posterior = saved_model['posterior']\n",
    "    prior = saved_model['prior']\n",
    "else:\n",
    "    posterior = lstm_model(lstm_input_size, lstm_output_size, args.rnn_size, args.posterior_rnn_layers, cfg.BASIC.BATCH_SIZE)\n",
    "    prior = lstm_model(lstm_input_size, lstm_output_size, args.rnn_size, args.prior_rnn_layers, cfg.BASIC.BATCH_SIZE)\n",
    "\n",
    "    posterior.apply(utils.init_weights)\n",
    "    prior.apply(utils.init_weights)\n",
    "\n",
    "import models.model_predictor as model\n",
    "       \n",
    "if args.model_dir != '':\n",
    "    decoder = saved_model['decoder']\n",
    "    encoder = saved_model['encoder']\n",
    "else:\n",
    "    encoder = model.encoder_conv(args.g_dim, args.channels)\n",
    "    decoder = model.decoder_conv(args.g_dim, args.channels, height=(args.image_width / 16) - 2, width=(args.image_width / 16) - 2)\n",
    "    encoder.apply(utils.init_weights)\n",
    "    decoder.apply(utils.init_weights)\n",
    "\n",
    "pose_network = model.pose_network(16, 14, 14, 13)\n",
    "conv_network = model.conv_network(16+args.g_dim+int(args.z_dim/4), args.g_dim)\n",
    "pose_network.apply(utils.init_weights)\n",
    "conv_network.apply(utils.init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.optimizer = optim.Adam\n",
    "\n",
    "posterior_optimizer = args.optimizer(posterior.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "prior_optimizer = args.optimizer(prior.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "encoder_optimizer = args.optimizer(encoder.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "decoder_optimizer = args.optimizer(decoder.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "pose_network_optimizer = args.optimizer(pose_network.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "conv_network_optimizer = args.optimizer(conv_network.parameters(), lr=args.lr, betas=(args.beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- loss functions ------------------------------------\n",
    "class Loss(nn.Module):\n",
    "    def __init__(self, cfg, device, mode, beta):\n",
    "        super(Loss, self).__init__()\n",
    "        self.loss_dict = {}\n",
    "        self.count = 0\n",
    "        self.device = device\n",
    "        self.l1_loss = nn.SmoothL1Loss()\n",
    "        self.batch_size = cfg.BASIC.BATCH_SIZE\n",
    "        self.mode = mode\n",
    "        self.beta = beta\n",
    "        \n",
    "        self.loss_dict[\"Model based BC {}/kl loss\".format(self.mode)] = 0\n",
    "        self.loss_dict[\"Model based BC {}/l1 loss\".format(self.mode)] = 0\n",
    "        self.loss_dict[\"Model based BC {}/loss\".format(self.mode)] = 0\n",
    "        \n",
    "    def get_log(self):\n",
    "        for key in self.loss_dict.keys():\n",
    "            self.loss_dict[key] /= self.count\n",
    "        return self.loss_dict\n",
    "    \n",
    "    def reset_log(self):\n",
    "        self.count = 0\n",
    "        for key in self.loss_dict.keys():\n",
    "            self.loss_dict[key] = 0\n",
    "    \n",
    "    def kl_criterion(self, mu1, logvar1, mu2, logvar2):\n",
    "        sigma1 = logvar1.mul(0.5).exp() \n",
    "        sigma2 = logvar2.mul(0.5).exp() \n",
    "        kld = torch.log(sigma2/sigma1) + (torch.exp(logvar1) + (mu1 - mu2)**2)/(2*torch.exp(logvar2)) - 1/2\n",
    "        kld = kld.sum() / self.batch_size\n",
    "        self.loss_dict[\"Model based BC {}/kl loss\".format(self.mode)] += kld.item()\n",
    "        \n",
    "        kld = self.beta * kld\n",
    "        self.loss_dict[\"Model based BC {}/loss\".format(self.mode)] += kld.item()\n",
    "        return kld\n",
    "    \n",
    "    def l1_criterion(self, pred_x, gt_x):\n",
    "        l1_loss = self.l1_loss(pred_x, gt_x)\n",
    "        self.loss_dict[\"Model based BC {}/l1 loss\".format(self.mode)] += l1_loss.item()\n",
    "        self.loss_dict[\"Model based BC {}/loss\".format(self.mode)] += l1_loss.item()\n",
    "        return l1_loss\n",
    "\n",
    "train_loss = Loss(cfg, 'cuda', 'train', args.beta)\n",
    "val_loss = Loss(cfg, 'cuda', 'val', args.beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv_network(\n",
       "  (pre_lstm): Sequential(\n",
       "    (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Tanh()\n",
       "    (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------- transfer to gpu ------------------------------------\n",
    "posterior.cuda()\n",
    "prior.cuda()\n",
    "encoder.cuda()\n",
    "decoder.cuda()\n",
    "pose_network.cuda()\n",
    "conv_network.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint\n",
    "if args.checkpoint_path != None:\n",
    "    checkpoint_path = os.path.join(args.checkpoint_path, 'mp.pth')\n",
    "    \n",
    "    if cfg.LOAD_MODEL == 'all':\n",
    "        model, optimizer, start_epoch, start_iter, scheduler = load_checkpoint(model, checkpoint_path, optimizer=optimizer, scheduler=scheduler)\n",
    "    elif cfg.LOAD_MODEL == 'model_only':\n",
    "        model, _, _, _, _ = load_checkpoint(model, checkpoint_path)\n",
    "        start_epoch, start_iter = 0, 1\n",
    "else:\n",
    "    start_epoch, start_iter = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_action(pose,rotation,grasp):\n",
    "    B,S,_ = pose.shape\n",
    "    rotation = rotation.view(B,S,-1)\n",
    "    grasp = torch.unsqueeze(grasp, 2)\n",
    "    \n",
    "    action = torch.cat([pose,rotation,grasp],2)\n",
    "    return action\n",
    "\n",
    "def plot(x, action, val_iter, index, mode):\n",
    "    posterior.hidden = posterior.init_hidden()\n",
    "    gen_seq = []\n",
    "    gen_seq.append(x[:,0])\n",
    "    for i in range(1, cfg.PRED_LEN + cfg.PAST_LEN):\n",
    "        h_conv = encoder(x[:,i-1])\n",
    "        h_target = encoder(x[:,i])[0]\n",
    "        \n",
    "        if args.last_frame_skip or i < cfg.PAST_LEN:\t\n",
    "            h_conv, skip = h_conv\n",
    "        else:\n",
    "            h_conv = h_conv[0]\n",
    "        \n",
    "        B,C,H,W = h_conv.shape\n",
    "        h = h_conv.view(B, H*W*args.g_dim)\n",
    "\n",
    "        h_conv = h_conv.detach()\n",
    "        h_target = h_target.detach()\n",
    "        z_t, _, _= posterior(h_target)\n",
    "        z_t = z_t.view(cfg.BASIC.BATCH_SIZE, -1, 14, 14)\n",
    "\n",
    "        if i < cfg.PAST_LEN:\n",
    "            gen_seq.append(x[:,i])\n",
    "        else:\n",
    "            z_d = pose_network(Variable(action[:,i-1].cuda())).detach()\n",
    "            h_pred = conv_network(torch.cat([h_conv, z_t, z_d], 1)).detach()\n",
    "            x_pred = decoder([h_pred, skip]).detach()\n",
    "            gen_seq.append(x_pred)\n",
    "\n",
    "    to_plot = []\n",
    "    nrow = min(cfg.BASIC.BATCH_SIZE, 10)\n",
    "    for i in range(nrow):\n",
    "        row = []\n",
    "        for t in range(cfg.PRED_LEN + cfg.PAST_LEN):\n",
    "            row.append(gen_seq[t][i]) \n",
    "        to_plot.append(row)\n",
    "    fname = '%s/rec_%d_%d_%s.png' % (checkpoint_dir, val_iter, index, mode) \n",
    "    utils.save_tensors_image(fname, to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iter: 000100/150000, Cost: 14.77s, Load: 2.39, Forward: 4.95, Backward: 6.23, Loss: 0.005509\n",
      "===> Iter: 000200/150000, Cost: 11.84s, Load: 0.91, Forward: 4.03, Backward: 5.79, Loss: 0.003087\n",
      "===> Iter: 000300/150000, Cost: 12.06s, Load: 1.09, Forward: 3.92, Backward: 5.87, Loss: 0.003077\n",
      "===> Iter: 000400/150000, Cost: 12.55s, Load: 1.00, Forward: 4.42, Backward: 5.93, Loss: 0.002588\n",
      "===> Iter: 000500/150000, Cost: 12.43s, Load: 0.96, Forward: 4.45, Backward: 5.82, Loss: 0.002149\n",
      "===> Iter: 000600/150000, Cost: 12.58s, Load: 1.31, Forward: 4.25, Backward: 5.88, Loss: 0.002198\n",
      "===> Iter: 000700/150000, Cost: 12.16s, Load: 0.98, Forward: 4.17, Backward: 5.93, Loss: 0.002043\n",
      "===> Iter: 000800/150000, Cost: 11.92s, Load: 0.90, Forward: 4.12, Backward: 5.70, Loss: 0.002357\n",
      "===> Iter: 000900/150000, Cost: 12.55s, Load: 1.00, Forward: 4.49, Backward: 5.86, Loss: 0.002752\n",
      "===> Iter: 001000/150000, Cost: 12.42s, Load: 1.20, Forward: 4.14, Backward: 5.99, Loss: 0.002213\n",
      "===> Iter: 001100/150000, Cost: 12.37s, Load: 0.98, Forward: 4.31, Backward: 5.86, Loss: 0.002463\n",
      "===> Iter: 001200/150000, Cost: 12.43s, Load: 1.01, Forward: 4.36, Backward: 5.85, Loss: 0.002270\n",
      "===> Iter: 001300/150000, Cost: 12.64s, Load: 1.61, Forward: 4.02, Backward: 5.90, Loss: 0.002933\n",
      "===> Iter: 001400/150000, Cost: 11.97s, Load: 0.94, Forward: 3.96, Backward: 5.93, Loss: 0.002501\n",
      "===> Iter: 001500/150000, Cost: 12.13s, Load: 0.87, Forward: 4.10, Backward: 5.74, Loss: 0.002282\n",
      "===> Iter: 001600/150000, Cost: 12.20s, Load: 1.08, Forward: 4.19, Backward: 5.81, Loss: 0.001920\n",
      "===> Iter: 001700/150000, Cost: 11.94s, Load: 1.02, Forward: 4.08, Backward: 5.75, Loss: 0.002290\n",
      "===> Iter: 001800/150000, Cost: 12.03s, Load: 1.04, Forward: 3.83, Backward: 5.88, Loss: 0.002501\n",
      "===> Iter: 001900/150000, Cost: 12.07s, Load: 0.90, Forward: 4.11, Backward: 5.82, Loss: 0.003074\n",
      "===> Iter: 002000/150000, Cost: 12.12s, Load: 0.94, Forward: 4.20, Backward: 5.78, Loss: 0.002350\n",
      "===> Iter: 002100/150000, Cost: 12.08s, Load: 0.92, Forward: 4.19, Backward: 5.74, Loss: 0.002579\n",
      "===> Iter: 002200/150000, Cost: 11.98s, Load: 0.93, Forward: 3.88, Backward: 5.93, Loss: 0.003359\n",
      "===> Iter: 002300/150000, Cost: 12.21s, Load: 0.87, Forward: 4.04, Backward: 5.97, Loss: 0.003168\n",
      "===> Iter: 002400/150000, Cost: 12.27s, Load: 0.95, Forward: 4.15, Backward: 6.02, Loss: 0.003025\n",
      "===> Iter: 002500/150000, Cost: 12.12s, Load: 1.05, Forward: 4.15, Backward: 5.71, Loss: 0.003199\n",
      "===> Iter: 002600/150000, Cost: 12.29s, Load: 1.05, Forward: 4.09, Backward: 5.79, Loss: 0.003365\n",
      "===> Iter: 002700/150000, Cost: 12.48s, Load: 1.03, Forward: 4.39, Backward: 5.89, Loss: 0.002537\n",
      "===> Iter: 002800/150000, Cost: 11.83s, Load: 0.85, Forward: 4.07, Backward: 5.73, Loss: 0.002818\n",
      "===> Iter: 002900/150000, Cost: 11.92s, Load: 0.93, Forward: 4.09, Backward: 5.79, Loss: 0.003113\n",
      "===> Iter: 003000/150000, Cost: 11.86s, Load: 0.93, Forward: 4.05, Backward: 5.79, Loss: 0.002872\n",
      "===> Iter: 003100/150000, Cost: 12.39s, Load: 1.08, Forward: 4.38, Backward: 5.75, Loss: 0.003165\n",
      "===> Iter: 003200/150000, Cost: 12.13s, Load: 1.02, Forward: 4.14, Backward: 5.80, Loss: 0.004713\n",
      "===> Iter: 003300/150000, Cost: 12.02s, Load: 1.06, Forward: 3.94, Backward: 5.79, Loss: 0.003387\n",
      "===> Iter: 003400/150000, Cost: 12.45s, Load: 0.96, Forward: 4.44, Backward: 5.84, Loss: 0.003681\n",
      "===> Iter: 003500/150000, Cost: 11.90s, Load: 0.90, Forward: 3.91, Backward: 5.74, Loss: 0.003076\n",
      "===> Iter: 003600/150000, Cost: 12.24s, Load: 1.05, Forward: 4.21, Backward: 5.72, Loss: 0.003197\n",
      "===> Iter: 003700/150000, Cost: 12.46s, Load: 0.89, Forward: 4.34, Backward: 5.88, Loss: 0.003478\n",
      "===> Iter: 003800/150000, Cost: 11.68s, Load: 0.89, Forward: 3.75, Backward: 5.70, Loss: 0.003100\n",
      "===> Iter: 003900/150000, Cost: 10.89s, Load: 0.70, Forward: 3.28, Backward: 5.65, Loss: 0.004175\n",
      "===> Iter: 004000/150000, Cost: 10.83s, Load: 0.67, Forward: 3.25, Backward: 5.65, Loss: 0.003704\n",
      "===> Iter: 004100/150000, Cost: 10.87s, Load: 0.74, Forward: 3.26, Backward: 5.63, Loss: 0.003369\n",
      "===> Iter: 004200/150000, Cost: 10.91s, Load: 0.67, Forward: 3.28, Backward: 5.68, Loss: 0.003497\n",
      "===> Iter: 004300/150000, Cost: 12.09s, Load: 1.29, Forward: 3.51, Backward: 5.99, Loss: 0.005074\n",
      "===> Iter: 004400/150000, Cost: 11.89s, Load: 0.73, Forward: 3.66, Backward: 6.21, Loss: 0.003758\n",
      "===> Iter: 004500/150000, Cost: 11.90s, Load: 0.65, Forward: 3.66, Backward: 6.22, Loss: 0.003258\n",
      "===> Iter: 004600/150000, Cost: 11.38s, Load: 0.70, Forward: 3.48, Backward: 5.90, Loss: 0.004529\n",
      "===> Iter: 004700/150000, Cost: 11.63s, Load: 0.72, Forward: 3.53, Backward: 6.04, Loss: 0.003849\n",
      "===> Iter: 004800/150000, Cost: 10.93s, Load: 0.74, Forward: 3.32, Backward: 5.65, Loss: 0.004330\n",
      "===> Iter: 004900/150000, Cost: 11.12s, Load: 0.91, Forward: 3.30, Backward: 5.67, Loss: 0.003512\n",
      "===> Iter: 005000/150000, Cost: 10.85s, Load: 0.71, Forward: 3.26, Backward: 5.65, Loss: 0.003777\n",
      "validation start\n",
      "===> Iter: 005000/150000, VAL Loss: 0.003004\n",
      "\n",
      "===> Iter: 005100/150000, Cost: 16.42s, Load: 0.69, Forward: 3.61, Backward: 6.15, Loss: 0.002923\n",
      "===> Iter: 005200/150000, Cost: 12.03s, Load: 0.75, Forward: 3.68, Backward: 6.22, Loss: 0.003613\n",
      "===> Iter: 005300/150000, Cost: 11.41s, Load: 0.71, Forward: 3.47, Backward: 5.93, Loss: 0.003221\n",
      "===> Iter: 005400/150000, Cost: 10.94s, Load: 0.79, Forward: 3.27, Backward: 5.64, Loss: 0.003128\n",
      "===> Iter: 005500/150000, Cost: 10.87s, Load: 0.70, Forward: 3.29, Backward: 5.64, Loss: 0.003087\n",
      "===> Iter: 005600/150000, Cost: 11.11s, Load: 0.72, Forward: 3.33, Backward: 5.76, Loss: 0.003702\n",
      "===> Iter: 005700/150000, Cost: 11.81s, Load: 0.67, Forward: 3.62, Backward: 6.19, Loss: 0.003090\n",
      "===> Iter: 005800/150000, Cost: 12.34s, Load: 1.10, Forward: 3.67, Backward: 6.23, Loss: 0.003934\n",
      "===> Iter: 005900/150000, Cost: 12.25s, Load: 1.11, Forward: 3.62, Backward: 6.16, Loss: 0.003978\n",
      "===> Iter: 006000/150000, Cost: 11.87s, Load: 0.69, Forward: 3.63, Backward: 6.22, Loss: 0.004245\n",
      "===> Iter: 006100/150000, Cost: 11.74s, Load: 0.69, Forward: 3.60, Backward: 6.14, Loss: 0.004107\n",
      "===> Iter: 006200/150000, Cost: 11.84s, Load: 0.71, Forward: 3.63, Backward: 6.20, Loss: 0.004256\n",
      "===> Iter: 006300/150000, Cost: 11.89s, Load: 0.68, Forward: 3.66, Backward: 6.21, Loss: 0.003324\n",
      "===> Iter: 006400/150000, Cost: 11.87s, Load: 0.69, Forward: 3.67, Backward: 6.17, Loss: 0.003602\n",
      "===> Iter: 006500/150000, Cost: 11.84s, Load: 0.67, Forward: 3.65, Backward: 6.18, Loss: 0.002853\n",
      "===> Iter: 006600/150000, Cost: 11.87s, Load: 0.68, Forward: 3.64, Backward: 6.21, Loss: 0.003249\n",
      "===> Iter: 006700/150000, Cost: 11.84s, Load: 0.64, Forward: 3.61, Backward: 6.18, Loss: 0.003963\n",
      "===> Iter: 006800/150000, Cost: 11.86s, Load: 0.68, Forward: 3.63, Backward: 6.21, Loss: 0.003851\n",
      "===> Iter: 006900/150000, Cost: 11.87s, Load: 0.68, Forward: 3.63, Backward: 6.22, Loss: 0.003865\n",
      "===> Iter: 007000/150000, Cost: 11.88s, Load: 0.68, Forward: 3.64, Backward: 6.19, Loss: 0.003259\n",
      "===> Iter: 007100/150000, Cost: 11.19s, Load: 0.67, Forward: 3.40, Backward: 5.83, Loss: 0.004304\n",
      "===> Iter: 007200/150000, Cost: 11.12s, Load: 0.78, Forward: 3.37, Backward: 5.66, Loss: 0.004188\n",
      "===> Iter: 007300/150000, Cost: 10.80s, Load: 0.65, Forward: 3.24, Backward: 5.63, Loss: 0.003607\n",
      "===> Iter: 007400/150000, Cost: 11.82s, Load: 1.47, Forward: 3.38, Backward: 5.72, Loss: 0.004265\n",
      "===> Iter: 007500/150000, Cost: 11.00s, Load: 0.70, Forward: 3.34, Backward: 5.70, Loss: 0.003243\n",
      "===> Iter: 007600/150000, Cost: 10.89s, Load: 0.70, Forward: 3.27, Backward: 5.66, Loss: 0.004449\n",
      "===> Iter: 007700/150000, Cost: 10.98s, Load: 0.68, Forward: 3.32, Backward: 5.66, Loss: 0.003527\n",
      "===> Iter: 007800/150000, Cost: 10.95s, Load: 0.67, Forward: 3.33, Backward: 5.68, Loss: 0.004047\n",
      "===> Iter: 007900/150000, Cost: 10.86s, Load: 0.67, Forward: 3.26, Backward: 5.66, Loss: 0.003931\n",
      "===> Iter: 008000/150000, Cost: 11.01s, Load: 0.87, Forward: 3.27, Backward: 5.66, Loss: 0.003409\n",
      "===> Iter: 008100/150000, Cost: 10.85s, Load: 0.66, Forward: 3.28, Backward: 5.65, Loss: 0.004038\n",
      "===> Iter: 008200/150000, Cost: 10.84s, Load: 0.67, Forward: 3.26, Backward: 5.63, Loss: 0.003901\n",
      "===> Iter: 008300/150000, Cost: 11.10s, Load: 0.67, Forward: 3.38, Backward: 5.77, Loss: 0.004595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iter: 008400/150000, Cost: 11.80s, Load: 0.69, Forward: 3.61, Backward: 6.17, Loss: 0.004573\n",
      "===> Iter: 008500/150000, Cost: 11.83s, Load: 0.69, Forward: 3.63, Backward: 6.18, Loss: 0.005040\n",
      "===> Iter: 008600/150000, Cost: 11.78s, Load: 0.67, Forward: 3.60, Backward: 6.16, Loss: 0.004006\n",
      "===> Iter: 008700/150000, Cost: 11.00s, Load: 0.67, Forward: 3.31, Backward: 5.74, Loss: 0.004323\n",
      "===> Iter: 008800/150000, Cost: 10.91s, Load: 0.67, Forward: 3.29, Backward: 5.68, Loss: 0.005070\n",
      "===> Iter: 008900/150000, Cost: 10.87s, Load: 0.70, Forward: 3.26, Backward: 5.64, Loss: 0.004072\n",
      "===> Iter: 009000/150000, Cost: 10.83s, Load: 0.66, Forward: 3.27, Backward: 5.64, Loss: 0.004702\n",
      "===> Iter: 009100/150000, Cost: 11.09s, Load: 0.79, Forward: 3.36, Backward: 5.69, Loss: 0.005106\n",
      "===> Iter: 009200/150000, Cost: 10.95s, Load: 0.70, Forward: 3.33, Backward: 5.65, Loss: 0.004806\n",
      "===> Iter: 009300/150000, Cost: 10.86s, Load: 0.65, Forward: 3.27, Backward: 5.64, Loss: 0.004431\n",
      "===> Iter: 009400/150000, Cost: 10.93s, Load: 0.69, Forward: 3.32, Backward: 5.66, Loss: 0.003690\n",
      "===> Iter: 009500/150000, Cost: 11.86s, Load: 0.95, Forward: 3.53, Backward: 6.07, Loss: 0.003489\n",
      "===> Iter: 009600/150000, Cost: 11.86s, Load: 0.70, Forward: 3.63, Backward: 6.21, Loss: 0.003952\n",
      "===> Iter: 009700/150000, Cost: 11.90s, Load: 0.70, Forward: 3.65, Backward: 6.22, Loss: 0.005361\n",
      "===> Iter: 009800/150000, Cost: 11.84s, Load: 0.65, Forward: 3.63, Backward: 6.20, Loss: 0.003103\n",
      "===> Iter: 009900/150000, Cost: 11.84s, Load: 0.66, Forward: 3.62, Backward: 6.19, Loss: 0.004008\n",
      "===> Iter: 010000/150000, Cost: 11.87s, Load: 0.66, Forward: 3.66, Backward: 6.19, Loss: 0.004839\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for dimension 1 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3939339a5e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrasp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-08401c5e3a91>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(x, action, val_iter, index, mode)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRED_LEN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAST_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mh_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mh_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_frame_skip\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAST_LEN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 1 with size 4"
     ]
    }
   ],
   "source": [
    "# start train\n",
    "tic = time.time()\n",
    "end = time.time()\n",
    "trained_time = 0\n",
    "# max_iter = cfg.BASIC.MAX_EPOCH * len(train_dataloader)\n",
    "max_iter = cfg.BASIC.MAX_ITER\n",
    "time_dict = Time_dict()\n",
    "load_start = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, cfg.BASIC.MAX_EPOCH):\n",
    "    for iteration, inputs in enumerate(train_dataloader, 1):\n",
    "        time_dict.load_data += time.time() - load_start\n",
    "        total_iteration = len(train_dataloader) * epoch + iteration\n",
    "            \n",
    "        # skip until start iter\n",
    "        if iteration < start_iter:\n",
    "            continue\n",
    "            \n",
    "        x = inputs[\"rgb\"].cuda()\n",
    "        pose = inputs[\"pose_xyz\"].cuda()\n",
    "        rotation = inputs[\"rotation_matrix\"].cuda()\n",
    "        grasp = inputs[\"grasp\"].cuda()\n",
    "\n",
    "        action = make_action(pose, rotation, grasp)\n",
    "\n",
    "        B,S,C,H,W = x.shape\n",
    "\n",
    "        posterior.zero_grad()\n",
    "        prior.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        pose_network.zero_grad()\n",
    "        conv_network.zero_grad()\n",
    "\n",
    "        # initialize the hidden state.\n",
    "        posterior.hidden = posterior.init_hidden()\n",
    "        prior.hidden = prior.init_hidden()\n",
    "\n",
    "        l1 = 0\n",
    "        kld = 0\n",
    "        \n",
    "        # forward\n",
    "        with Timer() as t:\n",
    "            for sequence_index in range(1, S-1):\n",
    "                h_conv = encoder(x[:,sequence_index-1])\n",
    "                h_target = encoder(x[:,sequence_index])[0]\n",
    "                if args.last_frame_skip or sequence_index < cfg.PAST_LEN:\t\n",
    "                    h_conv, skip = h_conv\n",
    "                else:\n",
    "                    h_conv = h_conv[0]\n",
    "\n",
    "                B,C,H,W = h_conv.shape\n",
    "                h = h_conv.view(B, H*W*args.g_dim)\n",
    "\n",
    "                z_t, mu, logvar = posterior(h_target)\n",
    "                z_t = z_t.view(cfg.BASIC.BATCH_SIZE, -1, 14, 14)\n",
    "                _, mu_p, logvar_p = prior(h)\n",
    "\n",
    "                z_d = pose_network(action[:,sequence_index])\n",
    "                h_pred = conv_network(torch.cat([h_conv, z_t, z_d], 1))\n",
    "\n",
    "                x_pred = decoder([h_pred, skip])\n",
    "\n",
    "                l1 += train_loss.l1_criterion(x_pred, x[:,sequence_index])\n",
    "                kld += train_loss.kl_criterion(mu, logvar, mu_p, logvar_p)\n",
    "                train_loss.count += 1\n",
    "                \n",
    "            loss = l1 + kld*args.beta\n",
    "        time_dict.forward += t.secs\n",
    "        \n",
    "        # backward\n",
    "        with Timer() as t:\n",
    "            loss.backward()\n",
    "            posterior_optimizer.step()\n",
    "            prior_optimizer.step()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            pose_network_optimizer.step()\n",
    "            conv_network_optimizer.step()\n",
    "        time_dict.backward += t.secs\n",
    "\n",
    "        \n",
    "        # time setting\n",
    "        trained_time += time.time() - end\n",
    "        end = time.time() \n",
    "        \n",
    "        # save and print log\n",
    "        if total_iteration % args.log_step == 0:\n",
    "            log = train_loss.get_log()\n",
    "            eta_seconds = int((trained_time / total_iteration) * (max_iter - total_iteration))\n",
    "            \n",
    "            if (args.log2wandb) and (total_iteration % (args.log_step * 10)):\n",
    "                wandb.log(log,step=total_iteration)\n",
    "            \n",
    "            # print(threading.active_count())\n",
    "            print('===> Iter: {:06d}/{:06d}, Cost: {:.2f}s, Load: {:.2f}, Forward: {:.2f}, Backward: {:.2f}, Loss: {:.6f}'.format(total_iteration, \n",
    "                max_iter,  time.time() - tic, \n",
    "                time_dict.load_data, time_dict.forward, time_dict.backward, log[\"Model based BC train/loss\"]))\n",
    "            \n",
    "            train_loss.reset_log()\n",
    "            tic = time.time()\n",
    "            time_dict.reset()\n",
    "        \n",
    "        # save checkpoint\n",
    "        if total_iteration % args.save_step == 0:\n",
    "            checkpoint_dir = os.path.join(model_path,'checkpoint_iter{}'.format(total_iteration))\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            \n",
    "            posterior_path = os.path.join(checkpoint_dir, 'posterior.pth')\n",
    "            save_checkpoint(posterior, posterior_optimizer, epoch, iteration, posterior_path)\n",
    "            \n",
    "            prior_path = os.path.join(checkpoint_dir, 'prior.pth')\n",
    "            save_checkpoint(prior, prior_optimizer, epoch, iteration, prior_path)\n",
    "            \n",
    "            encoder_path = os.path.join(checkpoint_dir, 'encoder.pth')\n",
    "            save_checkpoint(encoder, encoder_optimizer, epoch, iteration, encoder_path)\n",
    "            \n",
    "            decoder_path = os.path.join(checkpoint_dir, 'decoder.pth')\n",
    "            save_checkpoint(decoder, decoder_optimizer, epoch, iteration, decoder_path)\n",
    "            \n",
    "            pose_network_path = os.path.join(checkpoint_dir, 'pose_network.pth')\n",
    "            save_checkpoint(pose_network, pose_network_optimizer, epoch, iteration, pose_network_path)\n",
    "            \n",
    "            conv_network_path = os.path.join(checkpoint_dir, 'conv_network.pth')\n",
    "            save_checkpoint(conv_network, conv_network_optimizer, epoch, iteration, conv_network_path)\n",
    "            \n",
    "            # save output image\n",
    "            for i, inputs in enumerate(train_dataloader, 1):\n",
    "                with torch.no_grad():\n",
    "                    x = inputs[\"rgb\"].cuda()\n",
    "                    pose = inputs[\"pose_xyz\"].cuda()\n",
    "                    rotation = inputs[\"rotation_matrix\"].cuda()\n",
    "                    grasp = inputs[\"grasp\"].cuda()\n",
    "\n",
    "                    action = make_action(pose, rotation, grasp)\n",
    "                    plot(x, action, total_iteration, i, \"train\")\n",
    "                    \n",
    "                if i >= 5:\n",
    "                    break\n",
    "            \n",
    "            for i, inputs in enumerate(val_dataloader, 1):\n",
    "                with torch.no_grad():\n",
    "                    x = inputs[\"rgb\"].cuda()\n",
    "                    pose = inputs[\"pose_xyz\"].cuda()\n",
    "                    rotation = inputs[\"rotation_matrix\"].cuda()\n",
    "                    grasp = inputs[\"grasp\"].cuda()\n",
    "\n",
    "                    action = make_action(pose, rotation, grasp)\n",
    "                    plot(x, action, total_iteration, i, \"val\")\n",
    "                    \n",
    "                if i >= 5:\n",
    "                    break\n",
    "\n",
    "        # validation\n",
    "        if total_iteration % args.eval_step == 0:\n",
    "            print('validation start')\n",
    "            for iteration, inputs in enumerate(val_dataloader, 1):\n",
    "                with torch.no_grad():\n",
    "                    x = inputs[\"rgb\"].cuda()\n",
    "                    pose = inputs[\"pose_xyz\"].cuda()\n",
    "                    rotation = inputs[\"rotation_matrix\"].cuda()\n",
    "                    grasp = inputs[\"grasp\"].cuda()\n",
    "\n",
    "                    action = make_action(pose, rotation, grasp)\n",
    "                    B,S,C,H,W = x.shape\n",
    "\n",
    "                    # initialize the hidden state.\n",
    "                    posterior.hidden = posterior.init_hidden()\n",
    "                    prior.hidden = prior.init_hidden()\n",
    "\n",
    "                    l1 = 0\n",
    "                    kld = 0\n",
    "\n",
    "                    # forward\n",
    "                    for sequence_index in range(1, S-1):\n",
    "                        h_conv = encoder(x[:,sequence_index-1])\n",
    "                        h_target = encoder(x[:,sequence_index])[0]\n",
    "                        if args.last_frame_skip or sequence_index < cfg.PAST_LEN:\t\n",
    "                            h_conv, skip = h_conv\n",
    "                        else:\n",
    "                            h_conv = h_conv[0]\n",
    "\n",
    "                        B,C,H,W = h_conv.shape\n",
    "                        h = h_conv.view(B, H*W*args.g_dim)\n",
    "\n",
    "                        z_t, mu, logvar = posterior(h_target)\n",
    "                        z_t = z_t.view(cfg.BASIC.BATCH_SIZE, -1, 14, 14)\n",
    "                        _, mu_p, logvar_p = prior(h)\n",
    "\n",
    "                        z_d = pose_network(action[:,sequence_index])\n",
    "                        h_pred = conv_network(torch.cat([h_conv, z_t, z_d], 1))\n",
    "\n",
    "                        x_pred = decoder([h_pred, skip])\n",
    "\n",
    "                        l1 += val_loss.l1_criterion(x_pred, x[:,sequence_index])\n",
    "                        kld += val_loss.kl_criterion(mu, logvar, mu_p, logvar_p)\n",
    "                        val_loss.count += 1\n",
    "\n",
    "                    if iteration >= 100:\n",
    "                        break\n",
    "            \n",
    "            val_log = val_loss.get_log()\n",
    "            if args.log2wandb:\n",
    "                wandb.log(val_log,step=total_iteration)\n",
    "            \n",
    "            print('===> Iter: {:06d}/{:06d}, VAL Loss: {:.6f}'.format(total_iteration, max_iter, val_log['Model based BC val/loss']))\n",
    "            print('')\n",
    "            val_loss.reset_log()        \n",
    "\n",
    "        load_start = time.time()\n",
    "\n",
    "        if total_iteration == cfg.BASIC.MAX_ITER:\n",
    "            sys.exit()\n",
    "\n",
    "    train_dataset.update_seed()\n",
    "    print(\"seed: {}\".format(train_dataset.seed))\n",
    "    start_iter = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = inputs[\"rgb\"].cuda()\n",
    "pose = inputs[\"pose_xyz\"].cuda()\n",
    "rotation = inputs[\"rotation_matrix\"].cuda()\n",
    "grasp = inputs[\"grasp\"].cuda()\n",
    "\n",
    "action = make_action(pose, rotation, grasp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 13])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "B,S,C,H,W = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 512, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "posterior.zero_grad()\n",
    "prior.zero_grad()\n",
    "encoder.zero_grad()\n",
    "decoder.zero_grad()\n",
    "pose_network.zero_grad()\n",
    "conv_network.zero_grad()\n",
    "\n",
    "# initialize the hidden state.\n",
    "posterior.hidden = posterior.init_hidden()\n",
    "prior.hidden = prior.init_hidden()\n",
    "\n",
    "l1 = 0\n",
    "kld = 0\n",
    "\n",
    "for i in range(1, S-1):\n",
    "    h_conv = encoder(x[:,i-1])\n",
    "    h_target = encoder(x[:,i])[0]\n",
    "    if args.last_frame_skip or i < cfg.PAST_LEN:\t\n",
    "        h_conv, skip = h_conv\n",
    "    else:\n",
    "        h_conv = h_conv[0]\n",
    "    \n",
    "    B,C,H,W = h_conv.shape\n",
    "    h = h_conv.view(B, H*W*args.g_dim)\n",
    "\n",
    "    z_t, mu, logvar = posterior(h_target)\n",
    "    z_t = z_t.view(cfg.BASIC.BATCH_SIZE, -1, 14, 14)\n",
    "    _, mu_p, logvar_p = prior(h)\n",
    "\n",
    "    z_d = pose_network(action[:,i])\n",
    "    h_pred = conv_network(torch.cat([h_conv, z_t, z_d], 1))\n",
    "\n",
    "    x_pred = decoder([h_pred, skip])\n",
    "\n",
    "    l1 += l1_criterion(x_pred, x[:,i])\n",
    "    kld += kl_criterion(mu, logvar, mu_p, logvar_p)\n",
    "\n",
    "loss = l1 + kld*args.beta\n",
    "loss.backward()\n",
    "\n",
    "posterior_optimizer.step()\n",
    "prior_optimizer.step()\n",
    "encoder_optimizer.step()\n",
    "decoder_optimizer.step()\n",
    "pose_network_optimizer.step()\n",
    "conv_network_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.zero_grad()\n",
    "prior.zero_grad()\n",
    "encoder.zero_grad()\n",
    "decoder.zero_grad()\n",
    "pose_network.zero_grad()\n",
    "conv_network.zero_grad()\n",
    "\n",
    "# initialize the hidden state.\n",
    "posterior.hidden = posterior.init_hidden()\n",
    "prior.hidden = prior.init_hidden()\n",
    "\n",
    "l1 = 0\n",
    "kld = 0\n",
    "for i in range(1, args.n_past+args.n_future):\n",
    "    h_conv = encoder(x[i-1])\n",
    "    h_target = encoder(x[i])[0]\n",
    "    if args.last_frame_skip or i < args.n_past:\t\n",
    "        h_conv, skip = h_conv\n",
    "    else:\n",
    "        h_conv = h_conv[0]\n",
    "    h = h_conv.view(-1, 4*args.g_dim)\n",
    "\n",
    "    z_t, mu, logvar = posterior(h_target)\n",
    "    z_t = z_t.view(-1, int(args.z_dim/4), 2, 2)\n",
    "    _, mu_p, logvar_p = prior(h)\n",
    "\n",
    "    z_d = pose_network(Variable(diff_pose[i-1].cuda()))\n",
    "    h_pred = conv_network(torch.cat([h_conv, z_t, z_d], 1))\n",
    "\n",
    "    x_pred = decoder([h_pred, skip])\n",
    "\n",
    "    l1 += l1_criterion(x_pred, x[i])\n",
    "    kld += kl_criterion(mu, logvar, mu_p, logvar_p)\n",
    "\n",
    "loss = l1 + kld*args.beta\n",
    "loss.backward()\n",
    "\n",
    "posterior_optimizer.step()\n",
    "prior_optimizer.step()\n",
    "encoder_optimizer.step()\n",
    "decoder_optimizer.step()\n",
    "pose_network_optimizer.step()\n",
    "conv_network_optimizer.step()\n",
    "\n",
    "return l1.data.cpu().numpy()/(cfg.PRED_LEN+cfg.PAST_LEN), kld.data.cpu().numpy()/(cfg.PRED_LEN+cfg.PAST_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
