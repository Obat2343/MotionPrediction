{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtendon\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import tensorboardX\n",
    "import torch\n",
    "import yaml\n",
    "import shutil\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn as nn\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kornia requires version >= 3.6. your version 3.6\n"
     ]
    }
   ],
   "source": [
    "from pycode.dataset import RLBench_dataset, Softargmax_dataset, imageaug_full_transform, train_val_split, pose_aug\n",
    "from pycode.config import _C as cfg\n",
    "from pycode.model.Hourglass import stacked_hourglass_model\n",
    "from pycode.loss.mp_loss import Train_Loss_sequence_hourglass\n",
    "from pycode.misc import save_outputs, build_model_MP, build_dataset_MP, build_optimizer, str2bool, save_args, save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configration file ../configs/HMD_MP.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">soft-argmax/hoge</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/tendon/MotionPrediction-jupyter\" target=\"_blank\">https://wandb.ai/tendon/MotionPrediction-jupyter</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/tendon/MotionPrediction-jupyter/runs/f8gdxrvi\" target=\"_blank\">https://wandb.ai/tendon/MotionPrediction-jupyter/runs/f8gdxrvi</a><br/>\n",
       "                Run data is saved locally in <code>/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/jupyter/wandb/run-20210326_173907-f8gdxrvi</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parser\n",
    "parser = argparse.ArgumentParser(description='parser for image generator')\n",
    "parser.add_argument('--config_file', type=str, default='', metavar='FILE', help='path to config file')\n",
    "parser.add_argument('--log_step', type=int, default=10, help='')\n",
    "parser.add_argument('--save_step', type=int, default=100, help='')\n",
    "parser.add_argument('--eval_step', type=int, default=100, help='')\n",
    "parser.add_argument('--output_dirname', type=str, default='', help='')\n",
    "parser.add_argument('--checkpoint_path', type=str, default=None, help='')\n",
    "parser.add_argument('--log2wandb', type=str2bool, default=True)\n",
    "args = parser.parse_args(args=['--config_file','../configs/HMD_MP.yaml','--output_dirname',''])\n",
    "# args = parser.parse_args(args=['--checkpoint_path','output/2020-04-02_18:28:18.736004/model_log/checkpoint_epoch9_iter11'])\n",
    "\n",
    "# get cfg data\n",
    "if len(args.config_file) > 0:\n",
    "    print('Loaded configration file {}'.format(args.config_file))\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "\n",
    "# define output dirname\n",
    "if len(args.output_dirname) == 0:\n",
    "    dt_now = datetime.datetime.now()\n",
    "    output_dirname = str(dt_now.date()) + '_' + str(dt_now.time())\n",
    "else:\n",
    "    output_dirname = args.output_dirname\n",
    "    \n",
    "cfg.BASIC.OUTPUT_DIR = os.path.join(cfg.BASIC.OUTPUT_DIR, cfg.DATASET.NAME, output_dirname)\n",
    "cfg.freeze()\n",
    "\n",
    "# difine save model path\n",
    "model_path = os.path.join(cfg.BASIC.OUTPUT_DIR, 'model_log')\n",
    "\n",
    "# make output dir\n",
    "os.makedirs(cfg.BASIC.OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# copy config file\n",
    "if len(args.config_file) > 0:\n",
    "    shutil.copy(args.config_file,cfg.BASIC.OUTPUT_DIR)\n",
    "\n",
    "# save args\n",
    "argsfile_path = os.path.join(cfg.BASIC.OUTPUT_DIR, \"args.txt\")\n",
    "save_args(args,argsfile_path)\n",
    "\n",
    "# set seed and cuda\n",
    "torch.manual_seed(cfg.BASIC.SEED)\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(cfg.BASIC.DEVICE)\n",
    "\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.manual_seed(cfg.BASIC.SEED)\n",
    "\n",
    "with open('../configs/HMD_MP.yaml') as file:\n",
    "    obj = yaml.safe_load(file)\n",
    "\n",
    "if args.log2wandb:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    run = wandb.init(project='MotionPrediction-{}'.format(cfg.DATASET.NAME), entity='tendon', config=obj, save_code=True, name=args.output_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of future is 3 frame\n",
      "load dataset\n",
      "length of future is 3 frame\n",
      "create dataset\n",
      "save dataset\n"
     ]
    }
   ],
   "source": [
    "# set dataset\n",
    "train_dataset = build_dataset_MP(cfg, save_dataset=False, mode='train')\n",
    "val_dataset = build_dataset_MP(cfg, save_dataset=True, mode='val')\n",
    "\n",
    "# set dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=cfg.BASIC.BATCH_SIZE, shuffle=True, num_workers=cfg.BASIC.WORKERS)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=cfg.BASIC.BATCH_SIZE, shuffle=False, num_workers=cfg.BASIC.WORKERS)\n",
    "\n",
    "# set model\n",
    "model = build_model_MP(cfg)\n",
    "# wandb.watch(model, log_freq=5000)\n",
    "model = torch.nn.DataParallel(model, device_ids = list(range(cfg.BASIC.NUM_GPU)))\n",
    "# model = convert_model(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# set loss\n",
    "train_loss = Train_Loss_sequence_hourglass(cfg, device)\n",
    "val_loss = Train_Loss_sequence_hourglass(cfg, device)\n",
    "\n",
    "# set optimizer\n",
    "optimizer = build_optimizer(cfg, model, 'mp')\n",
    "scheduler = StepLR(optimizer, step_size=cfg.SCHEDULER.STEPLR.STEP_SIZE, gamma=cfg.SCHEDULER.STEPLR.GAMMA)\n",
    "\n",
    "# load checkpoint\n",
    "if args.checkpoint_path != None:\n",
    "    checkpoint_path = os.path.join(args.checkpoint_path, 'mp.pth')\n",
    "    \n",
    "    if cfg.LOAD_MODEL == 'all':\n",
    "        model, optimizer, start_epoch, start_iter, scheduler = load_checkpoint(model, checkpoint_path, optimizer=optimizer, scheduler=scheduler)\n",
    "    elif cfg.LOAD_MODEL == 'model_only':\n",
    "        model, _, _, _, _ = load_checkpoint(model, checkpoint_path)\n",
    "        start_epoch, start_iter = 0, 1\n",
    "else:\n",
    "    start_epoch, start_iter = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Iter: 000010/5234000, LR: 0.00010, Cost: 23.75s, Eta: 143 days, 21:08:43, Loss: 31.694034\n",
      "===> Iter: 000020/5234000, LR: 0.00010, Cost: 12.20s, Eta: 108 days, 21:37:07, Loss: 27.835903\n",
      "===> Iter: 000030/5234000, LR: 0.00010, Cost: 11.87s, Eta: 96 days, 13:31:24, Loss: 30.275351\n",
      "===> Iter: 000040/5234000, LR: 0.00010, Cost: 12.69s, Eta: 91 days, 15:31:13, Loss: 32.586755\n",
      "===> Iter: 000050/5234000, LR: 0.00010, Cost: 13.49s, Eta: 89 days, 15:52:44, Loss: 26.796971\n",
      "===> Iter: 000060/5234000, LR: 0.00010, Cost: 13.01s, Eta: 87 days, 20:34:31, Loss: 24.715724\n",
      "===> Iter: 000070/5234000, LR: 0.00010, Cost: 12.83s, Eta: 86 days, 9:46:24, Loss: 18.830889\n",
      "===> Iter: 000080/5234000, LR: 0.00010, Cost: 14.10s, Eta: 86 days, 6:44:05, Loss: 15.659781\n",
      "===> Iter: 000090/5234000, LR: 0.00010, Cost: 13.52s, Eta: 85 days, 19:00:26, Loss: 15.222691\n",
      "===> Iter: 000100/5234000, LR: 0.00010, Cost: 12.91s, Eta: 85 days, 0:47:41, Loss: 13.676780\n",
      "validataion start\n",
      "===> Iter: 000100/5234000, VAL Loss: 14.911268\n",
      "\n",
      "===> Iter: 000110/5234000, LR: 0.00010, Cost: 193.55s, Eta: 183 days, 21:25:41, Loss: 14.492260\n",
      "===> Iter: 000120/5234000, LR: 0.00010, Cost: 13.79s, Eta: 175 days, 12:45:16, Loss: 13.917695\n",
      "===> Iter: 000130/5234000, LR: 0.00010, Cost: 14.24s, Eta: 168 days, 15:59:49, Loss: 14.702034\n",
      "===> Iter: 000140/5234000, LR: 0.00010, Cost: 14.64s, Eta: 162 days, 22:53:06, Loss: 14.799885\n",
      "===> Iter: 000150/5234000, LR: 0.00010, Cost: 13.46s, Eta: 157 days, 12:34:28, Loss: 13.859054\n",
      "===> Iter: 000160/5234000, LR: 0.00010, Cost: 13.72s, Eta: 152 days, 20:55:07, Loss: 12.675952\n",
      "===> Iter: 000170/5234000, LR: 0.00010, Cost: 13.30s, Eta: 148 days, 14:50:44, Loss: 12.560369\n",
      "===> Iter: 000180/5234000, LR: 0.00010, Cost: 13.53s, Eta: 144 days, 22:00:26, Loss: 8.533402\n",
      "===> Iter: 000190/5234000, LR: 0.00010, Cost: 13.80s, Eta: 141 days, 16:33:51, Loss: 9.534404\n",
      "===> Iter: 000200/5234000, LR: 0.00010, Cost: 13.70s, Eta: 138 days, 18:08:56, Loss: 8.186571\n",
      "validataion start\n",
      "===> Iter: 000200/5234000, VAL Loss: 7.877273\n",
      "\n",
      "===> Iter: 000210/5234000, LR: 0.00010, Cost: 192.02s, Eta: 187 days, 12:55:48, Loss: 7.644891\n",
      "===> Iter: 000220/5234000, LR: 0.00010, Cost: 13.79s, Eta: 182 days, 19:28:36, Loss: 7.241967\n",
      "===> Iter: 000230/5234000, LR: 0.00010, Cost: 13.80s, Eta: 178 days, 11:56:10, Loss: 5.439041\n",
      "===> Iter: 000240/5234000, LR: 0.00010, Cost: 13.88s, Eta: 174 days, 13:29:17, Loss: 6.381254\n",
      "===> Iter: 000250/5234000, LR: 0.00010, Cost: 13.29s, Eta: 170 days, 19:10:09, Loss: 5.886724\n",
      "===> Iter: 000260/5234000, LR: 0.00010, Cost: 14.13s, Eta: 167 days, 12:29:58, Loss: 5.470154\n",
      "===> Iter: 000270/5234000, LR: 0.00010, Cost: 14.30s, Eta: 164 days, 12:36:21, Loss: 5.335992\n",
      "===> Iter: 000280/5234000, LR: 0.00010, Cost: 14.31s, Eta: 161 days, 17:51:38, Loss: 4.784135\n",
      "===> Iter: 000290/5234000, LR: 0.00010, Cost: 13.81s, Eta: 159 days, 1:13:17, Loss: 4.364856\n",
      "===> Iter: 000300/5234000, LR: 0.00010, Cost: 13.21s, Eta: 156 days, 9:59:17, Loss: 4.173009\n",
      "validataion start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f507c8ae978>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/env/dl21/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/env/dl21/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 47, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f507d0e57f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/env/dl21/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/env/dl21/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 47, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/env/dl21/local/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 27999) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-43df457f2016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/env/dl21/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[0;32m/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/env/dl21/local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/env/dl21/local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/dl00/dl001/tendon/project/Imitation_Learning/MotionPrediction/env/dl21/local/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "end = time.time()\n",
    "trained_time = 0\n",
    "max_iter = cfg.BASIC.MAX_EPOCH * len(train_dataloader)\n",
    "for epoch in range(start_epoch, cfg.BASIC.MAX_EPOCH):\n",
    "    for iteration, inputs in enumerate(train_dataloader, 1):\n",
    "        total_iteration = len(train_dataloader) * epoch + iteration\n",
    "            \n",
    "        # skip until start iter\n",
    "        if iteration < start_iter:\n",
    "            continue\n",
    "            \n",
    "        # optimize generator\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = train_loss(inputs, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # time setting\n",
    "        trained_time += time.time() - end\n",
    "        end = time.time() \n",
    "        \n",
    "        # save and print log\n",
    "        if total_iteration % args.log_step == 0:\n",
    "            log = train_loss.get_log()\n",
    "            eta_seconds = int((trained_time / total_iteration) * (max_iter - total_iteration))\n",
    "            \n",
    "            if args.log2wandb:\n",
    "                wandb.log(log,step=total_iteration)\n",
    "            \n",
    "            print('===> Iter: {:06d}/{:06d}, LR: {:.5f}, Cost: {:.2f}s, Eta: {}, Loss: {:.6f}'.format(total_iteration, \n",
    "                max_iter, optimizer.param_groups[0]['lr'], time.time() - tic, \n",
    "                str(datetime.timedelta(seconds=eta_seconds)), log['train/weight_loss']))\n",
    "            \n",
    "            train_loss.reset_log()\n",
    "            tic = time.time()\n",
    "            \n",
    "        # validataion\n",
    "        if total_iteration % args.eval_step == 0:\n",
    "            print('validataion start')\n",
    "            for iteration, inputs in enumerate(val_dataloader, 1):\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    _ = val_loss(inputs, outputs, mode='val')\n",
    "            \n",
    "            val_log = val_loss.get_log()\n",
    "            if args.log2wandb:\n",
    "                wandb.log(val_log,step=total_iteration)\n",
    "            \n",
    "            print('===> Iter: {:06d}/{:06d}, VAL Loss: {:.6f}'.format(total_iteration, max_iter, val_log['val/weight_loss']))\n",
    "            print('')\n",
    "            val_loss.reset_log()\n",
    "        \n",
    "        # save checkpoint\n",
    "        if total_iteration % args.save_step == 0:\n",
    "            checkpoint_dir = os.path.join(model_path,'checkpoint_epoch{}_iter{}'.format(epoch,iteration))\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            cp_path = os.path.join(checkpoint_dir, 'mp.pth')\n",
    "            save_checkpoint(model, optimizer, epoch, iteration, cp_path, scheduler)\n",
    "            \n",
    "            # save output image\n",
    "            for i, inputs in enumerate(train_dataloader, 1):\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    save_outputs(inputs, outputs, checkpoint_dir, i, cfg, mode='train')\n",
    "                    \n",
    "                if i >= 5:\n",
    "                    break\n",
    "            \n",
    "            for i, inputs in enumerate(val_dataloader, 1):\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    save_outputs(inputs, outputs, checkpoint_dir, i, cfg, mode='val')\n",
    "                    \n",
    "                if i >= 5:\n",
    "                    break        \n",
    "                \n",
    "    train_dataset.update_seed()\n",
    "    print(\"seed: {}\".format(train_dataset.seed))\n",
    "    start_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
